{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dh6bVHUagIqv",
        "outputId": "cf98b152-2f69-4628-cc78-bb6875dd8192"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mtcnn\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (2.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.21.6)\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.1.1\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "!pip install mtcnn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FACE EXTRACTION\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from time import time\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from mtcnn.mtcnn import MTCNN, extract_face\n",
        "#from pkg.mtcnn import MTCNN, extract_face\n",
        "\n",
        "######################################################################\n",
        "\n",
        "ALBUM_PATH = os.path.join(os.path.dirname(__file__), '..', 'data', 'album')\n",
        "FACES_PATH = os.path.join(os.path.dirname(__file__), '..', 'data', 'faces')\n",
        "\n",
        "######################################################################\n",
        "\n",
        "def extract_album_faces():\n",
        "    \"\"\" Extract all the faces from the album that have a detection probability > 99%\n",
        "    and save them in a `data/faces` folder.\n",
        "    \"\"\"\n",
        "    np.random.seed(0)\n",
        "    os.makedirs(os.path.abspath(FACES_PATH), exist_ok=True)\n",
        "    mtcnn = MTCNN(select_largest=False, keep_all=True, device='cpu').eval()\n",
        "    for root, dirs, files in os.walk(ALBUM_PATH):\n",
        "        for fname in tqdm(files, ascii=True):\n",
        "            fpath = os.path.join(ALBUM_PATH, fname)\n",
        "            img = Image.open(fpath)\n",
        "            with torch.no_grad():\n",
        "                boxes, probs = mtcnn.detect(img, landmarks=False)\n",
        "            if boxes is not None:\n",
        "                for box, prob in zip(boxes, probs):\n",
        "                    if prob > 0.99:\n",
        "                        isfile = True\n",
        "                        while isfile: \n",
        "                            rand_key = np.random.randint(10**5, 10**6)\n",
        "                            save_path = os.path.join(FACES_PATH, '{}.png'.format(rand_key))\n",
        "                            isfile = os.path.isfile(save_path)\n",
        "                        _ = extract_face(img, box, save_path=save_path)\n",
        "\n",
        "\n",
        "######################################################################\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Extracting faces from photo album\")\n",
        "    t0 = time()\n",
        "    extract_album_faces()\n",
        "    print(\"Done ({:.2f}s)\".format(time() - t0))"
      ],
      "metadata": {
        "id": "KQiWgj8vrUYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VIDEO PROCESSING\n",
        "\n",
        "# video_facenet/video.py\n",
        "class VideoProcessor:\n",
        "    def __init__(self, video_path, **kwargs):\n",
        "        self.video_path = video_path\n",
        "        self.cap = cv2.VideoCapture(video_path)\n",
        "        self.id = 0\n",
        "        self.data = kwargs           \n",
        "\n",
        "    @property\n",
        "    def duration(self):\n",
        "        cap = self.cap\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        return frame_count/fps\n",
        "\n",
        "    @property\n",
        "    def pos(self):\n",
        "        return int(self.cap.get(cv2.CAP_PROP_POS_FRAMES))\n",
        "\n",
        "    @pos.setter\n",
        "    def pos(self, pos):\n",
        "        self.id = pos\n",
        "        self.cap.set(cv2.CAP_PROP_POS_FRAMES, pos) \n",
        "  \n",
        "\n",
        "    def images(self, start=0, end=None):\n",
        "        self.pos = start\n",
        "        success, image = self.cap.read()\n",
        "        while success:\n",
        "            if end is not None and self.id == end:\n",
        "                yield image\n",
        "                return\n",
        "\n",
        "            yield image\n",
        "            self.id += 1            \n",
        "            success, image = self.cap.read()                \n",
        "\n",
        "    def iterate(self, process, start=0, end=None):\n",
        "        last = self.frame_count - 1 if end is None else end \n",
        "        for image in self.images(start=start, end=end):\n",
        "            if process(image=image, pos=self.id, video=self, last=last, **self.data):\n",
        "                break"
      ],
      "metadata": {
        "id": "u0Q30fzDgkrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#HDBSCAN CLUSTERING\n",
        "from datetime import datetime\n",
        "import umap\n",
        "import joblib\n",
        "\n",
        "\n",
        "import warnings\n",
        "with warnings.catch_warnings():\n",
        "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)    \n",
        "    import hdbscan\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "from .files import file_name\n",
        "\n",
        "\n",
        "def cluster_faces_pipeline(reduce):\n",
        "    models = []\n",
        "    if reduce:\n",
        "        models.append(\n",
        "            (\"umap\", umap.UMAP(\n",
        "                n_neighbors=30,\n",
        "                min_dist=0.0,\n",
        "                n_components=30,\n",
        "                random_state=42,\n",
        "            ))\n",
        "        )\n",
        "    models.append((\"hdbscan\", hdbscan.HDBSCAN (min_cluster_size=15)))\n",
        "    return Pipeline(models)\n",
        "\n",
        "\n",
        "class FaceCluster(BaseEstimator):\n",
        "    def __init__(self, suffix, umap):\n",
        "        super()\n",
        "        self.suffix = suffix       \n",
        "        self.clusterer = cluster_faces_pipeline(reduce=umap)\n",
        "\n",
        "    @property\n",
        "    def _file_name(self):\n",
        "        return file_name(\"cluster{}.npy\", self.suffix)\n",
        "\n",
        "    def save(self):\n",
        "        joblib.dump(self.clusterer, self._file_name)\n",
        "\n",
        "    def load(self):\n",
        "        fn = self._file_name\n",
        "        if not os.path.isfile(fn):\n",
        "            return False\n",
        "        self.clusterer = joblib.load(fn)\n",
        "        return True        \n",
        "\n",
        "    @property\n",
        "    def hdbscan(self)->umap.UMAP:\n",
        "        return self.clusterer[\"hdbscan\"]\n",
        "\n",
        "    @property\n",
        "    def umap(self):\n",
        "        return self.clusterer[\"umap\"]        \n",
        "\n",
        "    @property\n",
        "    def labels_(self):\n",
        "        return self.hdbscan.labels_        \n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self.clusterer.fit(X, y)\n",
        "\n",
        "    def fit_predict(self, X, y=None):\n",
        "        start_time = datetime.now()        \n",
        "        rt = self.clusterer.fit_predict(X, y)\n",
        "        end_time = datetime.now()\n",
        "        print(\"Clustering took: {}\".format(end_time - start_time))        \n",
        "        return rt\n",
        "\n",
        "    def approximate_predict(self, X):\n",
        "        return hdbscan.approximate_predict(self.hdbscan, X)\n",
        "\n",
        "    def membership_vector(self, X):\n",
        "        return hdbscan.membership_vector(self.hdbscan, X)\n",
        "\n",
        "    @property\n",
        "    def probabilities_(self):\n",
        "        return self.hdbscan.probabilities_        \n",
        "\n",
        "    def all_points_membership_vectors(self):\n",
        "        return hdbscan.all_points_membership_vectors(self.hdbscan)\n",
        "\n",
        "    def generate_prediction_data(self):\n",
        "        self.hdbscan.generate_prediction_data()\n",
        "\n",
        "    def set_params(self, **kwargs):\n",
        "        return self.clusterer.set_params(**kwargs)"
      ],
      "metadata": {
        "id": "R0FReutRl2W6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PIPELINE\n",
        "from typing import List, cast\n",
        "from functools import partial\n",
        "\n",
        "from .facenet_types import Face\n",
        "from .video import VideoProcessor\n",
        "from .files import (\n",
        "    bounding_box_file_name,\n",
        "    landmarks_file_name,\n",
        "    embeddings_file_name    \n",
        ")\n",
        "\n",
        "def generate_embeddings(encoder, faces:List[Face], **kwargs):\n",
        "    images = [face.image for face in faces]\n",
        "    embeddings = encoder.generate_embeddings(images)\n",
        "    for face, embedding in zip(faces, embeddings):\n",
        "        face.embedding = embedding\n",
        "        face.image = None\n",
        "\n",
        "\n",
        "def find_faces(pos, detector, image, faces: List[Face], **kwargs):\n",
        "    found = cast(List[Face], detector.find_faces(image, detect_multiple_faces=True))\n",
        "    for i, face in enumerate(found):\n",
        "        face.pos = pos\n",
        "        face.id = i\n",
        "        faces.append(face)\n",
        "    \n",
        "class CsvWriter(object):\n",
        "    def __init__(self, file_name, append=False):\n",
        "        mode = \"a\" if append else \"w\"\n",
        "        self.f = open(file_name, mode)\n",
        "        self.new_line = \"\\n\"\n",
        "\n",
        "    def writeArray(self, *arr):\n",
        "        line = \",\".join([str(x) for x in arr])\n",
        "        self.f.write(line)\n",
        "        self.f.write(self.new_line)\n",
        "    \n",
        "    def flush(self):\n",
        "        self.f.flush()\n",
        "\n",
        "    def close(self):\n",
        "        self.f.close()\n",
        "\n",
        "class Saver(object):\n",
        "    def __init__(self, save, writers):\n",
        "        self.__save = save\n",
        "        self.__writers = writers\n",
        "\n",
        "    def __call__(self, **kwargs):\n",
        "        self.__save(**kwargs)\n",
        "\n",
        "    def flush(self):\n",
        "        for writer in self.__writers:\n",
        "            writer.flush()\n",
        "\n",
        "    def close(self):\n",
        "        for writer in self.__writers:\n",
        "            writer.close() \n",
        "\n",
        "\n",
        "def write_bounding_boxes(writer, pos, id, face):\n",
        "    writer.writeArray(pos, id, *face.bounding_box)\n",
        "\n",
        "def write_landmarks(writer, pos, id, landmarks):\n",
        "    for landmark in landmarks.items():\n",
        "        writer.writeArray(pos, id, landmark[0], landmark[1][0], landmark[1][1])\n",
        "\n",
        "def write_embeddings(writer, pos, id, embedding):\n",
        "    writer.writeArray(pos, id, *[writer.embedding_format % x for x in embedding])\n",
        "\n",
        "def save_faces(bounding_box_writer, landmarks_writer, embeddings_writer, faces:List[Face], **kwargs):              \n",
        "    for face in faces:\n",
        "        pos = face.pos\n",
        "        id = face.id\n",
        "        write_bounding_boxes(writer=bounding_box_writer, pos=pos, id=id, face=face)\n",
        "        write_landmarks(writer=landmarks_writer, pos=pos, id=id, landmarks=face.landmarks)\n",
        "        write_embeddings(writer=embeddings_writer, pos=pos, id=id, embedding=face.embedding)\n",
        "\n",
        "def create_faces_saver(suffix=\"\", embedding_format=\"%.6f\", append=False):\n",
        "    bounding_box_writer = CsvWriter(file_name=bounding_box_file_name(suffix), append=append)\n",
        "    landmarks_writer = CsvWriter(file_name=landmarks_file_name(suffix), append=append)\n",
        "    embeddings_writer = CsvWriter(file_name=embeddings_file_name(suffix), append=append)\n",
        "\n",
        "    writers = [bounding_box_writer, landmarks_writer, embeddings_writer]\n",
        "\n",
        "    embeddings_writer.embedding_format = embedding_format\n",
        "    save = partial(save_faces, bounding_box_writer=bounding_box_writer, landmarks_writer=landmarks_writer, embeddings_writer=embeddings_writer)\n",
        "\n",
        "    return Saver(save=save, writers=writers)\n",
        "\n",
        "def process_video(video_path, model_path, start=0, suffix=\"\", batch_size=64, end=None, **kwargs):\n",
        "    from video_facenet.facenet import Detector, Facenet\n",
        "\n",
        "    detector = Detector()\n",
        "    encoder = Facenet(\n",
        "        model_path=model_path,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "    faces = []\n",
        "\n",
        "    save = create_faces_saver(suffix=suffix)\n",
        "\n",
        "    def process(save, pos, faces, batch_size, last, **kwargs):\n",
        "        find_faces(faces=faces, pos=pos, **kwargs)\n",
        "        if len(faces) >= batch_size or pos==last:\n",
        "            generate_embeddings(faces=faces, **kwargs)\n",
        "            save(faces=faces, **kwargs)\n",
        "            save.flush()\n",
        "            faces.clear()\n",
        "            print(\"frame #\", pos)\n",
        "\n",
        "    video = VideoProcessor(video_path=video_path, detector=detector, encoder=encoder, save=save, faces=faces, batch_size=batch_size)\n",
        "    video.iterate(process, start=start, end=end)\n",
        "    save.close()\n",
        "    detector.close()\n",
        "    encoder.close()"
      ],
      "metadata": {
        "id": "yilYyCeDpLs4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}