{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "isQceZZbtlkD"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline  \n",
        "import IPython\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn.cluster\n",
        "from sklearn.decomposition import PCA\n",
        "import IPython.display as ipd\n",
        "from sklearn.manifold import TSNE\n",
        "import time\n",
        "import sklearn\n",
        "from sklearn.decomposition import PCA \n",
        "import librosa\n",
        "from sklearn import mixture\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "import librosa.display\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler,LabelEncoder\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def kmeans_model(train_data,n_clusters):\n",
        "    kmean=sklearn.cluster.KMeans(init='k-means++', n_clusters=n_clusters,n_init=200, max_iter=1000000)\n",
        "    kmean.fit(train_data)\n",
        "    # assign a cluster to each example\n",
        "    yhat = kmean.predict(train_data)\n",
        "    # retrieve unique clusters\n",
        "    clusters = unique(yhat)\n",
        "    return yhat,clusters"
      ],
      "metadata": {
        "id": "z5XRlo9It5cE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmean=sklearn.cluster.KMeans(n_clusters=5,n_jobs=4,max_iter=1000000)\n",
        "kmean.fit(train_data)\n",
        "\n",
        "def return_file_name(path):\n",
        "    return os.path.split(path)[1]\n",
        "\n",
        "\n",
        "clusters_kmean=[]\n",
        "for i in range(0,kmean.n_clusters):\n",
        "    new_cluster=raw_data.iloc[np.argwhere(kmean.predict(train_data)==i).T[0]]['audio'].str.strip()\n",
        "    new_cluster=new_cluster.map(return_file_name)\n",
        "    clusters_kmeanAgg.append(new_cluster)"
      ],
      "metadata": {
        "id": "f1L8T7KLuKc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,len(clusters_kmean)):\n",
        "    print('\\nCluster'+str(i)+'\\n')\n",
        "    print(clusters_kmean[i].sample(20,replace=True))\n",
        "    "
      ],
      "metadata": {
        "id": "yXFtxSnmuP0P"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Affinity Propagation\n",
        "def affinity(train_data,n_clusters):\n",
        "\n",
        "  af=sklearn.cluster.AffinityPropagation()\n",
        "  af.fit(train_data)\n",
        "  print('Number of clusters: '+str(len(af.cluster_centers_indices_)))"
      ],
      "metadata": {
        "id": "8XywRKwpuYA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def agglomerative_model(train_data,n_clusters):\n",
        "    agg=sklearn.cluster.AgglomerativeClustering(n_clusters=n_clusters)\n",
        "    # assign a cluster to each example\n",
        "    yhat = agg.fit_predict(train_data)\n",
        "    # retrieve unique clusters\n",
        "    clusters = unique(yhat)\n",
        "    return yhat,clusters"
      ],
      "metadata": {
        "id": "Fmq6QFBVuqLF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dbscan_model(train_data):\n",
        "    dbscan_model = sklearn.cluster.DBSCAN(eps = 0.5, min_samples = 20)\n",
        "    yhat = dbscan_model.fit_predict(train_data)\n",
        "    clusters=unique(yhat)\n",
        "    return yhat,clusters\n",
        "    "
      ],
      "metadata": {
        "id": "m6POheVnvHdE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optics_model(train_data):\n",
        "    optics_model = sklearn.cluster.OPTICS(eps=0.5, min_samples=20)\n",
        "   \n",
        "    yhat = optics_model.fit_predict(train_data)\n",
        "    clusters = unique(yhat)\n",
        "    return yhat,clusters"
      ],
      "metadata": {
        "id": "y1enLXDIwHbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pca_transform(train_data):\n",
        "    pca = PCA(n_components = 2) \n",
        "    X_principal = pca.fit_transform(train_data) \n",
        "    X_principal = pd.DataFrame(X_principal) \n",
        "    X_principal.columns = ['P1', 'P2'] \n",
        "    return X_principal\n",
        "    \n"
      ],
      "metadata": {
        "id": "p-oYrfaeutGu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_times(c_id, fname):\n",
        "    \n",
        "    \"\"\"Takes a segment \"\"\"    \n",
        "    \n",
        "    sample_name = '..' + fname.split('.')[2] + '.sample.seg'\n",
        "    \n",
        "    if int(c_id) == 0:\n",
        "        with open(sample_name, 'w'):\n",
        "            pass\n",
        "    \n",
        "    #read all from source\n",
        "    with open(fname, 'r') as sources:\n",
        "        lines = sources.readlines()\n",
        "        \n",
        "\n",
        "    for line in lines:\n",
        "        c = line[-2]\n",
        "        if c == c_id:\n",
        "            with open(sample_name, 'a+') as targets:\n",
        "                f_id, rest = line.split(' ')[0], \" \".join(line.split(' ')[1:])\n",
        "                f_mod = f_id + \"_s\" + str(c_id)\n",
        "                mod_line = \" \".join([f_mod, rest])\n",
        "                targets.write(mod_line)\n",
        "           \n",
        "            start, dur = int(line.split(' ')[2]), int(line.split(' ')[3])\n",
        "            start_sec, start_mil = start // 100, start % 100\n",
        "            dur_sec, dur_mil = dur // 100, dur % 100\n",
        "            #returns start times and durations in sox-readable format\n",
        "            #can be usedd for segmenting files according to samples\n",
        "            return \".\".join([str(start_sec), str(start_mil)]), \".\".join([str(dur_sec), str(dur_mil)])\n",
        "def get_times(c_id, fname):\n",
        "    \n",
        "    \"\"\"Takes a segment \"\"\"    \n",
        "    \n",
        "    sample_name = '..' + fname.split('.')[2] + '.sample.seg'\n",
        "  \n",
        "    if int(c_id) == 0:\n",
        "        with open(sample_name, 'w'):\n",
        "            pass\n",
        "    \n",
        "    #read all from source\n",
        "    with open(fname, 'r') as sources:\n",
        "        lines = sources.readlines()\n",
        "        \n",
        "    #gets the first line that belongs to the corresponding cluster (c_id)\n",
        "    #and after attaching a subfix to the file id, writes it to sample file\n",
        "    for line in lines:\n",
        "        c = line[-2]\n",
        "        if c == c_id:\n",
        "            with open(sample_name, 'a+') as targets:\n",
        "                f_id, rest = line.split(' ')[0], \" \".join(line.split(' ')[1:])\n",
        "                f_mod = f_id + \"_s\" + str(c_id)\n",
        "                mod_line = \" \".join([f_mod, rest])\n",
        "                targets.write(mod_line)\n",
        "           \n",
        "            start, dur = int(line.split(' ')[2]), int(line.split(' ')[3])\n",
        "            start_sec, start_mil = start // 100, start % 100\n",
        "            dur_sec, dur_mil = dur // 100, dur % 100\n",
        "            #returns start times and durations in sox-readable format\n",
        "            #can be usedd for segmenting files according to samples\n",
        "            return \".\".join([str(start_sec), str(start_mil)]), \".\".join([str(dur_sec), str(dur_mil)])\n"
      ],
      "metadata": {
        "id": "8Vbkj8u2vEgL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}