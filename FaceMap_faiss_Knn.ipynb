{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install infomap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV3PwRczXuep",
        "outputId": "2b810938-ca80-49f9-b942-5ae2e0adfbe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting infomap\n",
            "  Downloading infomap-2.6.0.tar.gz (261 kB)\n",
            "\u001b[K     |████████████████████████████████| 261 kB 4.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: infomap\n",
            "  Building wheel for infomap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for infomap: filename=infomap-2.6.0-cp37-cp37m-linux_x86_64.whl size=5607166 sha256=da50380618f89137cb09adb12091ce77ae8c6040e0120dcf8ecf2337b66e88e0\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/53/74/637a39ce6617c0f779fa1f955b30726fd5d32a94bd4960f73d\n",
            "Successfully built infomap\n",
            "Installing collected packages: infomap\n",
            "Successfully installed infomap-2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install libomp-dev\n",
        "!python -m pip install --upgrade faiss faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIVJTgrEYrGk",
        "outputId": "7c07a8ac-c40c-4976-c9b0-db0b7fa0a689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libomp5\n",
            "Suggested packages:\n",
            "  libomp-doc\n",
            "The following NEW packages will be installed:\n",
            "  libomp-dev libomp5\n",
            "0 upgraded, 2 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 239 kB of archives.\n",
            "After this operation, 804 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp-dev amd64 5.0.1-1 [5,088 B]\n",
            "Fetched 239 kB in 2s (159 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 155676 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Selecting previously unselected package libomp-dev.\n",
            "Preparing to unpack .../libomp-dev_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp-dev (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp-dev (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.5) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss\n",
            "  Downloading faiss-1.5.3-cp37-cp37m-manylinux1_x86_64.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 4.3 MB/s \n",
            "\u001b[?25hCollecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 85.5 MB 92 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from faiss) (1.21.6)\n",
            "Installing collected packages: faiss-gpu, faiss\n",
            "Successfully installed faiss-1.5.3 faiss-gpu-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu\n",
        "!pip install faiss-gpu\n",
        "#python3 -m pip install --upgrade faiss faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZmmQcl5ZWz-",
        "outputId": "f512c6ed-096b-4564-d96c-6f346caf2281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 3.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#faiss_knn\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import numpy as np\n",
        "import faiss\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "def l2norm(vec):\n",
        "    vec /= np.linalg.norm(vec, axis=1).reshape(-1, 1)\n",
        "    return vec\n",
        "\n",
        "\n",
        "def load_feat(feat_path, feat_dim=256):\n",
        "    if '.npy' in feat_path:\n",
        "        feat = np.load(feat_path).astype(np.float32)\n",
        "    else:\n",
        "        feat = np.fromfile(feat_path, dtype=np.float32)\n",
        "        feat = feat.reshape(-1, feat_dim)\n",
        "    return feat\n",
        "\n",
        "\n",
        "def faiss_knn(feat_path, knn_path, feat_dim, k=256):\n",
        "    feat = load_feat(feat_path, feat_dim)\n",
        "    print('features shape:', feat.shape)\n",
        "    feat = l2norm(feat)\n",
        "\n",
        "    index = faiss.IndexFlatIP(feat_dim)\n",
        "\n",
        "    # use single gpu\n",
        "    res = faiss.StandardGpuResources()\n",
        "    index = faiss.index_cpu_to_gpu(res, 0, index)\n",
        "\n",
        "    # use all gpus\n",
        "    # index = faiss.index_cpu_to_all_gpus(index)\n",
        "\n",
        "    index.add(feat)\n",
        "    batch_size = 200000\n",
        "    n = int(np.ceil(feat.shape[0] / batch_size))\n",
        "    sims = np.array([], dtype=np.float32).reshape(-1, k+1)\n",
        "    nbrs = np.array([], dtype=np.uint32).reshape(-1, k+1)\n",
        "\n",
        "    for i in tqdm(range(n)):\n",
        "        start = i * batch_size\n",
        "        end = (i+1) * batch_size\n",
        "        query = feat[start:end]\n",
        "        sim, nbr = index.search(query, k+1)\n",
        "        sims = np.vstack((sims, sim))\n",
        "        nbrs = np.vstack((nbrs, nbr))\n",
        "\n",
        "    # remove itself\n",
        "    for i in range(nbrs.shape[0]):\n",
        "        if i == nbrs[i, 0]:\n",
        "            pass\n",
        "        else:\n",
        "            for j, x in enumerate(nbrs[i, 1:]):\n",
        "                if i == x:\n",
        "                    nbrs[i, 1:j+1] = nbrs[i, :j]\n",
        "                    sims[i, 1:j+1] = sims[i, :j]\n",
        "                    break\n",
        "    sims = sims[:, 1:]\n",
        "    nbrs = nbrs[:, 1:]\n",
        "\n",
        "    x = [(np.array(nbr, dtype=np.uint32), np.array(sim, dtype=np.float32)) for nbr, sim in zip(nbrs, sims)]\n",
        "    np.savez_compressed(knn_path, data=np.array(x))\n",
        "    return nbrs, sims"
      ],
      "metadata": {
        "id": "-r7xBtdoYIkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#config\n",
        "\n",
        "window_size = 20\n",
        "topK = 256\n",
        "\n",
        "# MS1M feat_dim=256, CASIA and VGG feat_dim=512\n",
        "feat_dim = 256\n",
        "dataset = 'MS1M'\n",
        "test_name = 'part1_test'\n",
        "\n",
        "knn_path = './data/{}/knns/{}_faiss_top{}.npz'.format(dataset, test_name, topK)\n",
        "feat_path = './data/{}/features/{}.bin'.format(dataset, test_name)\n",
        "#label_path = './data/{}/labels/{}.meta'.format(dataset, test_name)\n",
        "result_path = './result/{}/part1_test_top{}_winds{}.npy'.format(dataset, topK, window_size)"
      ],
      "metadata": {
        "id": "UGH3ZqCxYUXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FN8JvwnWWbMS"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import os\n",
        "from time import time\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import infomap\n",
        "#from utlis.faiss_knn import faiss_knn\n",
        "#from configs import config\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "def outlier_detect(delta_p, window_size):\n",
        "    omega = window_size\n",
        "    z = np.zeros_like(delta_p, dtype=np.float32)\n",
        "    for j in tqdm(range(delta_p.shape[1]-omega, -1, -1)):\n",
        "        mu_test = np.mean(delta_p[:, j:j+omega], axis=1)\n",
        "        mu_ref = np.mean(delta_p[:, j:], axis=1)\n",
        "        sigma_ref = np.std(delta_p[:, j:], axis=1)\n",
        "        q = j + (omega+1)//2\n",
        "        z[:, q] = np.abs(mu_test - mu_ref) / sigma_ref\n",
        "    q_star = np.argmax(z, axis=1)\n",
        "    return q_star\n",
        "    \n",
        "\n",
        "\n",
        "class FaceMap():\n",
        "\n",
        "    def __init__(self):\n",
        "        self.omega = window_size\n",
        "        self.topK = topK\n",
        "        self.knn_path = knn_path\n",
        "        #self.label_path = label_path\n",
        "        self.feat_path = feat_path\n",
        "        self.feat_dim = feat_dim\n",
        "        self.result_path = result_path\n",
        "        os.makedirs(os.path.split(self.knn_path)[0], exist_ok=True)\n",
        "        os.makedirs(os.path.split(self.result_path)[0], exist_ok=True)\n",
        "        self._load_knn()\n",
        "        self.t = time()\n",
        "\n",
        "    def _load_knn(self):\n",
        "        t0 = time()\n",
        "        if os.path.exists(self.knn_path):\n",
        "            knn = np.load(self.knn_path)\n",
        "            knn = knn['data']\n",
        "            if isinstance(knn, list):\n",
        "                knn = np.array(knn)\n",
        "            self.nbrs = knn[:, 0, :self.topK].astype(np.int32)\n",
        "            self.sims = knn[:, 1, :self.topK].astype(np.float32)\n",
        "        else:\n",
        "            self.nbrs, self.sims = faiss_knn(self.feat_path, self.knn_path, self.feat_dim, self.topK)\n",
        "        print('time cost of load knn: {:.2f}s'.format(time() - t0))\n",
        "\n",
        "    def transition_prob_by_threshold(self, th=0.62):\n",
        "        single, links, weights = [], [], []\n",
        "        for i in tqdm(range(self.nbrs.shape[0])):\n",
        "            c = 0\n",
        "            for j, nbr in enumerate(self.nbrs[i]):\n",
        "                if self.sims[i, j] >= th:\n",
        "                    c += 1\n",
        "                    links.append((i, nbr))\n",
        "                    weights.append(self.sims[i, j])\n",
        "                else:\n",
        "                    break\n",
        "            if c == 0:\n",
        "                single.append(i)\n",
        "        self.links = np.array(links, dtype=np.uint32)\n",
        "        self.weights = np.array(weights, dtype=np.float32)\n",
        "        self.single = np.array(single, dtype=np.uint32)\n",
        "\n",
        "    def adjust_transition_prob(self):\n",
        "        p = self.sims / np.sum(self.sims, axis=1, keepdims=True)\n",
        "        t0 = time()\n",
        "        delta_p = p[:, :-1] - p[:, 1:]\n",
        "        q = outlier_detect(delta_p, self.omega)\n",
        "        print('time cost of outlier_detect: {:.2f}s'.format(time() - t0))\n",
        "        \n",
        "        single, links, weights = [], [], []\n",
        "        for i, k in enumerate(q):\n",
        "            count = 0\n",
        "            for idx, j in enumerate(self.nbrs[i, :k+1]):\n",
        "                if i == j:\n",
        "                    pass\n",
        "                else:\n",
        "                    count += 1\n",
        "                    links.append((i, j))\n",
        "                    weights.append(p[i, idx])\n",
        "            if count == 0:\n",
        "                single.append(i)\n",
        "        self.links = np.array(links, dtype=np.uint32)\n",
        "        self.weights = np.array(weights, dtype=np.float32)\n",
        "        self.single = np.array(single, dtype=np.uint32)\n",
        "    \n",
        "    def face_cluster(self):\n",
        "        info = infomap.Infomap(\"--two-level\", flow_model='undirected')\n",
        "        for (i, j), sim in tqdm(zip(self.links, self.weights)):\n",
        "            _ = info.addLink(i, j, sim)\n",
        "        del self.links\n",
        "        del self.weights\n",
        "\n",
        "        info.run(seed=100)\n",
        "\n",
        "        lb2idx = {}\n",
        "        self.idx2lb = {}\n",
        "        for node in info.iterTree():\n",
        "            if node.moduleIndex() not in lb2idx:\n",
        "                lb2idx[node.moduleIndex()] = []\n",
        "            lb2idx[node.moduleIndex()].append(node.physicalId)\n",
        "\n",
        "        for k, v in lb2idx.items():\n",
        "            if k == 0:\n",
        "                lb2idx[k] = v[2:]\n",
        "                for u in v[2:]:\n",
        "                    self.idx2lb[u] = k\n",
        "            else:\n",
        "                lb2idx[k] = v[1:]\n",
        "                for u in v[1:]:\n",
        "                    self.idx2lb[u] = k\n",
        "\n",
        "        lb_len = len(lb2idx)\n",
        "        if len(self.single) > 0:\n",
        "            for k in self.single:\n",
        "                if k in self.idx2lb:\n",
        "                    continue\n",
        "                self.idx2lb[k] = lb_len\n",
        "                lb2idx[lb_len] = [k]\n",
        "                lb_len += 1\n",
        "        print('time cost of FaceMap: {:.2f}s'.format(time() - self.t))\n",
        "\n",
        "        #pred_labels = np.zeros(len(self.idx2lb)) - 1\n",
        "        #for k, v in self.idx2lb.items():\n",
        "           # pred_labels[k] = v\n",
        "       # np.save(self.result_path, pred_labels)\n",
        "        np.save(self.result_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "face_map = FaceMap()\n",
        "face_map.adjust_transition_prob()\n",
        "face_map.face_cluster()"
      ],
      "metadata": {
        "id": "lXjKimDRW09R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "to prepare directory :\n",
        "https://github.com/yl-1993/learn-to-cluster/blob/master/DATASET.md\n"
      ],
      "metadata": {
        "id": "3ztK-n82js66"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K4B44hubdQ2z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}